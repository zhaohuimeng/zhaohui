{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "has proc: 1000\n",
      "has proc: 2000\n",
      "has proc: 3000\n",
      "has proc: 4000\n",
      "has proc: 5000\n",
      "has proc: 6000\n",
      "has proc: 7000\n",
      "has proc: 8000\n",
      "has proc: 9000\n",
      "has proc: 10000\n",
      "has proc: 11000\n",
      "has proc: 12000\n",
      "has proc: 13000\n",
      "has proc: 14000\n",
      "has proc: 15000\n",
      "has proc: 16000\n",
      "has proc: 17000\n",
      "has proc: 18000\n",
      "has proc: 19000\n",
      "load train data finish!\n",
      "Train on 15999 samples, validate on 4000 samples\n",
      "Epoch 1/15\n",
      "15999/15999 [==============================] - 55s 3ms/step - loss: 0.6915 - acc: 0.6960 - val_loss: 0.5150 - val_acc: 0.7805\n",
      "Epoch 2/15\n",
      "15999/15999 [==============================] - 55s 3ms/step - loss: 0.4532 - acc: 0.8167 - val_loss: 0.4475 - val_acc: 0.8225\n",
      "Epoch 3/15\n",
      "15999/15999 [==============================] - 59s 4ms/step - loss: 0.3863 - acc: 0.8527 - val_loss: 0.4264 - val_acc: 0.8282\n",
      "Epoch 4/15\n",
      "15999/15999 [==============================] - 57s 4ms/step - loss: 0.3277 - acc: 0.8757 - val_loss: 0.4260 - val_acc: 0.8335\n",
      "Epoch 5/15\n",
      "15999/15999 [==============================] - 56s 3ms/step - loss: 0.3003 - acc: 0.8907 - val_loss: 0.4272 - val_acc: 0.8355\n",
      "Epoch 6/15\n",
      "15999/15999 [==============================] - 54s 3ms/step - loss: 0.2756 - acc: 0.8987 - val_loss: 0.4295 - val_acc: 0.8325\n",
      "Epoch 7/15\n",
      "15999/15999 [==============================] - 55s 3ms/step - loss: 0.2561 - acc: 0.9071 - val_loss: 0.4446 - val_acc: 0.8347\n",
      "Epoch 8/15\n",
      "15999/15999 [==============================] - 55s 3ms/step - loss: 0.2369 - acc: 0.9173 - val_loss: 0.4516 - val_acc: 0.8357\n",
      "Epoch 9/15\n",
      "15999/15999 [==============================] - 59s 4ms/step - loss: 0.2218 - acc: 0.9232 - val_loss: 0.4764 - val_acc: 0.8377\n",
      "Epoch 10/15\n",
      "15999/15999 [==============================] - 56s 4ms/step - loss: 0.2096 - acc: 0.9257 - val_loss: 0.4774 - val_acc: 0.8375\n",
      "Epoch 11/15\n",
      "15999/15999 [==============================] - 55s 3ms/step - loss: 0.1934 - acc: 0.9334 - val_loss: 0.4766 - val_acc: 0.8370\n",
      "Epoch 12/15\n",
      "15999/15999 [==============================] - 56s 3ms/step - loss: 0.1860 - acc: 0.9339 - val_loss: 0.4995 - val_acc: 0.8390\n",
      "Epoch 13/15\n",
      "15999/15999 [==============================] - 56s 3ms/step - loss: 0.1741 - acc: 0.9369 - val_loss: 0.5178 - val_acc: 0.8353\n",
      "Epoch 14/15\n",
      "15999/15999 [==============================] - 56s 4ms/step - loss: 0.1682 - acc: 0.9424 - val_loss: 0.5087 - val_acc: 0.8365\n",
      "Epoch 15/15\n",
      "15999/15999 [==============================] - 55s 3ms/step - loss: 0.1584 - acc: 0.9466 - val_loss: 0.5346 - val_acc: 0.8352\n",
      "15999/15999 [==============================] - 7s 459us/step\n",
      "\n",
      "Train Acc: 0.962935188799\n"
     ]
    }
   ],
   "source": [
    "## LSTM ##\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Input, LSTM, Dense, Embedding\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "MAX_NUMBER = 4060\n",
    "\n",
    "def load_train_data(filename):\n",
    "    \n",
    "    x_raw_train = np.empty(19999,dtype=list)\n",
    "    y_raw_train = np.zeros((19999,3))\n",
    "    #x_raw_train = []\n",
    "    #y_raw_train = []\n",
    "    \n",
    "    pro_ind = 0\n",
    "    max_len_sent = 0\n",
    "    \n",
    "    with open(filename) as f1:\n",
    "        for line in f1:\n",
    "            line = line.strip('\\n').split('\\t')\n",
    "            \n",
    "            if len(line) != 2:\n",
    "                sys.stderr.write(\"train data format error\")\n",
    "                continue\n",
    "            try:\n",
    "                x = eval(line[0])\n",
    "                y = int(line[1])\n",
    "            except:\n",
    "                sys.stderr.write(\"train data decode error\")\n",
    "                continue\n",
    "            \n",
    "            x_raw_train[pro_ind] = x\n",
    "            t_temp = [0, 0, 0]\n",
    "            t_temp[y] = 1\n",
    "            #if y == 1:\n",
    "            #    t_temp = 0\n",
    "            #else:\n",
    "            #    t_temp = 1\n",
    "            y_raw_train[pro_ind] = t_temp\n",
    "            \n",
    "            lt = len(x)\n",
    "            if lt > max_len_sent:\n",
    "                max_len_sent = lt\n",
    "            \n",
    "            pro_ind += 1\n",
    "            if pro_ind % 1000 == 0:\n",
    "                print \"has proc: %d\" % pro_ind\n",
    "            \n",
    "    return [x_raw_train, y_raw_train, max_len_sent]\n",
    "            \n",
    "\n",
    "#def main():\n",
    "print \"Start!\"\n",
    "\n",
    "[x_train, y_train, max_len_sent] = load_train_data(\"train_data_encode\")\n",
    "print \"load train data finish!\"\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, max_len_sent)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)    \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_NUMBER, output_dim=128, input_length=max_len_sent))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "#x_train = x_train[:15000][:]\n",
    "#y_train = y_train[:15000][:]\n",
    "#x_test = x_train[-5000:][:]\n",
    "#y_test = y_train[-5000:][:]\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100,epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "result = model.evaluate(x_train,y_train,batch_size=1000)\n",
    "print '\\nTrain Acc:', result[1]\n",
    "\n",
    "#result = model.evaluate(x_test,y_test,batch_size=1000)\n",
    "#print '\\nTest Acc:', result[1]\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ..., 1882 2524 2282]\n",
      " [   0    0    0 ..., 1229 2701  820]\n",
      " [   0    0    0 ..., 3279 3493 1411]\n",
      " ..., \n",
      " [   0    0    0 ..., 3417 2779 3849]\n",
      " [   0    0    0 ..., 1771  961 2244]\n",
      " [   0    0    0 ...,  295 3882 3882]]\n",
      "[[0, 0, 1] [0, 1, 0] [0, 1, 0] ..., [0, 0, 1] [0, 0, 1] [1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print x_train\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
